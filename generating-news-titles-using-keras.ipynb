{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32649fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:39.237552Z",
     "iopub.status.busy": "2025-08-15T21:54:39.237330Z",
     "iopub.status.idle": "2025-08-15T21:54:54.790986Z",
     "shell.execute_reply": "2025-08-15T21:54:54.790408Z"
    },
    "papermill": {
     "duration": 15.558374,
     "end_time": "2025-08-15T21:54:54.792404",
     "exception": false,
     "start_time": "2025-08-15T21:54:39.234030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 21:54:41.511169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755294881.705252      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755294881.763626      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, Model, optimizers, losses, metrics, callbacks, utils, preprocessing, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e62199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:54.797915Z",
     "iopub.status.busy": "2025-08-15T21:54:54.797513Z",
     "iopub.status.idle": "2025-08-15T21:54:56.009953Z",
     "shell.execute_reply": "2025-08-15T21:54:56.009358Z"
    },
    "papermill": {
     "duration": 1.216401,
     "end_time": "2025-08-15T21:54:56.011335",
     "exception": false,
     "start_time": "2025-08-15T21:54:54.794934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_df = pl.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\n",
    "fake_df = pl.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6ab726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:56.016526Z",
     "iopub.status.busy": "2025-08-15T21:54:56.016072Z",
     "iopub.status.idle": "2025-08-15T21:54:56.058362Z",
     "shell.execute_reply": "2025-08-15T21:54:56.057633Z"
    },
    "papermill": {
     "duration": 0.045975,
     "end_time": "2025-08-15T21:54:56.059545",
     "exception": false,
     "start_time": "2025-08-15T21:54:56.013570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "char_ds = true_df.select('title').to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f8d764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:56.064484Z",
     "iopub.status.busy": "2025-08-15T21:54:56.064024Z",
     "iopub.status.idle": "2025-08-15T21:54:56.188495Z",
     "shell.execute_reply": "2025-08-15T21:54:56.187764Z"
    },
    "papermill": {
     "duration": 0.128016,
     "end_time": "2025-08-15T21:54:56.189626",
     "exception": false,
     "start_time": "2025-08-15T21:54:56.061610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_ds(text):\n",
    "    cleaned = text.lower()\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\s\\.,!?;:\\-\\'\\\"]', '', cleaned)\n",
    "    return cleaned\n",
    "\n",
    "char_ds = [clean_ds(text) for text in char_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86863682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:56.194329Z",
     "iopub.status.busy": "2025-08-15T21:54:56.194072Z",
     "iopub.status.idle": "2025-08-15T21:54:56.212354Z",
     "shell.execute_reply": "2025-08-15T21:54:56.211644Z"
    },
    "papermill": {
     "duration": 0.021809,
     "end_time": "2025-08-15T21:54:56.213393",
     "exception": false,
     "start_time": "2025-08-15T21:54:56.191584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "char_ds = ' '.join(char_ds)\n",
    "chars = sorted(list(set(char_ds)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "945f97a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:56.218090Z",
     "iopub.status.busy": "2025-08-15T21:54:56.217694Z",
     "iopub.status.idle": "2025-08-15T21:54:56.395987Z",
     "shell.execute_reply": "2025-08-15T21:54:56.395444Z"
    },
    "papermill": {
     "duration": 0.181907,
     "end_time": "2025-08-15T21:54:56.397247",
     "exception": false,
     "start_time": "2025-08-15T21:54:56.215340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "char_sentences = []\n",
    "char_next_chars = []\n",
    "for i in range(0, len(char_ds) - maxlen, step):\n",
    "    char_sentences.append(char_ds[i : i + maxlen])\n",
    "    char_next_chars.append(char_ds[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7656295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:54:56.402526Z",
     "iopub.status.busy": "2025-08-15T21:54:56.401879Z",
     "iopub.status.idle": "2025-08-15T21:55:02.410863Z",
     "shell.execute_reply": "2025-08-15T21:55:02.410281Z"
    },
    "papermill": {
     "duration": 6.012777,
     "end_time": "2025-08-15T21:55:02.412229",
     "exception": false,
     "start_time": "2025-08-15T21:54:56.399452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(char_sentences), maxlen, len(chars)), dtype=\"bool\")\n",
    "y = np.zeros((len(char_sentences), len(chars)), dtype=\"bool\")\n",
    "for i, sentence in enumerate(char_sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[char_next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc8def5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:55:02.417622Z",
     "iopub.status.busy": "2025-08-15T21:55:02.417392Z",
     "iopub.status.idle": "2025-08-15T21:55:04.492218Z",
     "shell.execute_reply": "2025-08-15T21:55:04.491632Z"
    },
    "papermill": {
     "duration": 2.078704,
     "end_time": "2025-08-15T21:55:04.493282",
     "exception": false,
     "start_time": "2025-08-15T21:55:02.414578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755294903.169710      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,192</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m90,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m6,192\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228,400</span> (892.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m228,400\u001b[0m (892.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228,400</span> (892.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m228,400\u001b[0m (892.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_model = models.Sequential(\n",
    "    [\n",
    "        Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128, return_sequences=True),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "char_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1089125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:55:04.499464Z",
     "iopub.status.busy": "2025-08-15T21:55:04.499237Z",
     "iopub.status.idle": "2025-08-15T21:55:04.513313Z",
     "shell.execute_reply": "2025-08-15T21:55:04.512633Z"
    },
    "papermill": {
     "duration": 0.018117,
     "end_time": "2025-08-15T21:55:04.514373",
     "exception": false,
     "start_time": "2025-08-15T21:55:04.496256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "char_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eefc9bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T21:55:04.519965Z",
     "iopub.status.busy": "2025-08-15T21:55:04.519765Z",
     "iopub.status.idle": "2025-08-15T22:03:02.109711Z",
     "shell.execute_reply": "2025-08-15T22:03:02.109047Z"
    },
    "papermill": {
     "duration": 477.594513,
     "end_time": "2025-08-15T22:03:02.111338",
     "exception": false,
     "start_time": "2025-08-15T21:55:04.516825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755294909.718562      67 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 11ms/step - categorical_accuracy: 0.2277 - loss: 2.7002 - val_categorical_accuracy: 0.3886 - val_loss: 2.0625\n",
      "Epoch 2/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - categorical_accuracy: 0.4269 - loss: 1.9474 - val_categorical_accuracy: 0.4683 - val_loss: 1.8010\n",
      "Epoch 3/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.4904 - loss: 1.7396 - val_categorical_accuracy: 0.4997 - val_loss: 1.6793\n",
      "Epoch 4/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5208 - loss: 1.6263 - val_categorical_accuracy: 0.5201 - val_loss: 1.6098\n",
      "Epoch 5/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5368 - loss: 1.5627 - val_categorical_accuracy: 0.5297 - val_loss: 1.5686\n",
      "Epoch 6/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5508 - loss: 1.5118 - val_categorical_accuracy: 0.5366 - val_loss: 1.5380\n",
      "Epoch 7/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5605 - loss: 1.4788 - val_categorical_accuracy: 0.5439 - val_loss: 1.5131\n",
      "Epoch 8/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5676 - loss: 1.4492 - val_categorical_accuracy: 0.5501 - val_loss: 1.4948\n",
      "Epoch 9/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5721 - loss: 1.4278 - val_categorical_accuracy: 0.5539 - val_loss: 1.4848\n",
      "Epoch 10/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5782 - loss: 1.4057 - val_categorical_accuracy: 0.5553 - val_loss: 1.4737\n",
      "Epoch 11/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5842 - loss: 1.3833 - val_categorical_accuracy: 0.5568 - val_loss: 1.4647\n",
      "Epoch 12/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5889 - loss: 1.3677 - val_categorical_accuracy: 0.5595 - val_loss: 1.4601\n",
      "Epoch 13/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5927 - loss: 1.3511 - val_categorical_accuracy: 0.5631 - val_loss: 1.4453\n",
      "Epoch 14/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5968 - loss: 1.3385 - val_categorical_accuracy: 0.5680 - val_loss: 1.4406\n",
      "Epoch 15/15\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - categorical_accuracy: 0.5980 - loss: 1.3304 - val_categorical_accuracy: 0.5672 - val_loss: 1.4411\n"
     ]
    }
   ],
   "source": [
    "char_history = char_model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    batch_size=128,\n",
    "    epochs=15,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4e65e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T22:03:02.796960Z",
     "iopub.status.busy": "2025-08-15T22:03:02.796196Z",
     "iopub.status.idle": "2025-08-15T22:03:43.998008Z",
     "shell.execute_reply": "2025-08-15T22:03:43.997265Z"
    },
    "papermill": {
     "duration": 41.555215,
     "end_time": "2025-08-15T22:03:43.999324",
     "exception": false,
     "start_time": "2025-08-15T22:03:02.444109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp:0.2\n",
      "united states republican party seeks to senate panel trump to state trump to seek republican senator considers to\n",
      "Temp:0.5\n",
      "united states congress says presidential report to u.s. house speaker ryan as attack adviser warns trump transgen\n",
      "Temp:0.6\n",
      "united states of meath manafort says new york urges u.s. senate confirms from host says trump calls to leave in r\n",
      "Temp:0.8\n",
      "united states: manafort's daare justice department about state to russia's capital case vote in saudi says with c\n",
      "Temp:1.0\n",
      "united states good fuil: saudi cartierd nypory april grout of tax regal pateride sanders macrans decenble takes b\n",
      "Temp:1.2\n",
      "united states state for trecitune' trump, rejoint necanaa honoutwan enerminate than sody pence to help cort per. \n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(model, start_string, num_chars_to_generate, maxlen, chars, char_indices, indices_char, temperature=1.0):\n",
    "    generated_text = start_string\n",
    "    sentence = \" \" * (maxlen - len(start_string)) + start_string\n",
    "    \n",
    "    for _ in range(num_chars_to_generate):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)), dtype=np.float32)\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated_text += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "for temp in [0.2, 0.5, 0.6, 0.8, 1.0, 1.2]:\n",
    "    print(f'Temp:{temp}')\n",
    "    text = generate_text(\n",
    "        char_model, \n",
    "        \"united states\", \n",
    "        100, \n",
    "        maxlen=maxlen, \n",
    "        chars=chars, \n",
    "        char_indices=char_indices, \n",
    "        indices_char=indices_char, \n",
    "        temperature=temp\n",
    "    )\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a191a",
   "metadata": {
    "papermill": {
     "duration": 0.358977,
     "end_time": "2025-08-15T22:03:44.659478",
     "exception": false,
     "start_time": "2025-08-15T22:03:44.300501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Hey everybody thanks for reading my notebook, this is my first attempt at anything NLP and I had a really cool time learning about different methods to preform text generation. However, if anybody knows how to preform text generation using keras or tensoflow better than this, maybe using a different dataset type or model architecture please do comment down below I really do appreciate it!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4831777,
     "sourceId": 8165591,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 553.456123,
   "end_time": "2025-08-15T22:03:48.658347",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-15T21:54:35.202224",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
